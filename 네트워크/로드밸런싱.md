### 로드 밸런싱

:heavy_check_mark: 개념

- 웹 사이트에 접속 인원이 굉장히 많으면 모든 트래픽을 감당하기에 1대의 서버로는 부족

- 대응 방안 

  - 하드웨어의 성능 올리기(Scale-up)
    - 향상 비용 비쌈
  - 여러 대의 서버가 나눠서 일하도록 만든다(Scale-out)
    - 서버가 여러대면 **무중단 서비스를 제공**하는 환경 구성이 용이

- **여러 서버에게 균등하게 트래픽을 분산** = `로드 밸런싱`

- `분산식 웹 서비스`로, 로드밸런서를 클라이언트와 서버 사이에 두고 부하가 일어나지 않도록 여러 서버에 분산

- 둘 혹은 셋 이상의 중앙처리장치 혹은 저장장치와 같은 컴퓨터 자원들에게 작업을 나눔

  ![image](https://user-images.githubusercontent.com/43842108/218710551-f73fbfe5-5e02-48b8-840e-ac2692295c45.png)

<br>

:heavy_check_mark:로드 밸런서(LB, Load Balancer)

- 로드 밸런싱 기술을 제공하는 서비스 또는 장치
- 클라이언트와 네트워크 트래픽이 집중되는 서버들 사이에 위치하며 VIP(Virtual IP)와 함께 구성
  - VIP
    - 로드 밸런싱의 대상이 되는 **여러 서버를 대표하는 가상의 IP**
    - 클라이언트들은 서버의 IP로 직접 요청을 하는 것이 아니라 LB가 가지고 있는 VIP를 대상으로 요청
    - LB는 설정된 부하 분산 방법에 따라 각 서버로 요청을 분산
- 특정 서버에 부하가 집중되지 않도록 트래픽을 다양한 방법으로 분산하여 서버들의 성능을 최적인 상태로 유지할 수 있도록 한다

<br>

:heavy_check_mark: 로드 밸런싱 알고리즘

1. 라운드 로빈

   - 시분할 시스템을 위해 설계된 스케쥴링 방식 중 하나

     - cf) 시분할 시스템 = cpu가 각 프로그램을 일정 시간동안 번갈아 가면서 실행

   - 프로세스들 사이에 우선순위를 두지 않고, **`순서대로` 일정 시간동안 cpu를 할당**하는 방식

   - 여러 개의 자원이 동일한 성능(스펙)이고, 서버와의 연결(세션)이 오래 지속되지 않을 경우에 적합

     <br>

2. 가중 라운드로빈 방식(Weighted)

   - 각각의 서버마다 가중치를 매기고 **가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분**

   - 주로 서버의 **트래픽 처리 능력이 상이한 경우 사용**되는 부하 분산 방식

   - EX

     - A 서버 = 5가중치, B서버=2가중치이면 => A서버에 5개, B서버에 2개의 요청 전달

     <br>

3. Least Connections(최소 연결)

   - **연결 개수가 가장 적은 서버를 선택**

     - 가장 많이 사용되는 방식

   - 트래픽으로 세션이 길어지는 경우 권장

   - 서버에 트래픽을 분배하는 것이 일정하지 않을 때 적합

     <br>

4. IP 해시 방식 (=Source)

   - **클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리**하는 방식

   - 사용자의 IP를 해싱해 로드를 분배하기 때문에 **사용자가 항상 동일한 서버로 연결되는 것을 보장**

     - cf) 해싱 = 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑

       <br>

5. 최소 리스폰 타임

   - **서버의 현재 연결 상태와 응답 시간을 고려하여 트래픽을 배분**하는 방식
     - cf) 응답 시간 = 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간
   - 가장 적은 연결 상태와 가장 짧은 응답시간을 보이는 서버에 우선적으로 로드 배분

   <br>

:heavy_check_mark: 이점

- 다운 타임 감소
  - 다운 타임 = 시스템을 이용할 수 없는 시간
- 확장 가능
- 중복성
- 유연성
- 효율

<br>

:heavy_check_mark: 종류

1. 운영체제 로드밸런서

   - 물리적 프로세서 간에 작업을 스케쥴링

   <br>

2. 네트워크 로드밸런서

   - 사용 가능한 백엔드에서 네트워크 작업을 스케쥴링

     <br>

     1. L2(Data Link Layer)

        - **Mac 주소를 바탕**으로 로드 밸런싱

        - 장점

          - 구조 간단, 신뢰성 높음, 가격 저렴, 성능 좋음

        - 단점

          - Broadcast 패킷에 의해 성능 저하 발생, 라우팅 등 상위 레이어 프로토콜 기반 스위칭 불가

          <br>

     2. L3(Network Layer)

        - **IP주소를 바탕**으로 로드 밸런싱

        - 장점

          - Broadcast 트래픽으로 전체 성능 저하 방지, 트래픽 체크

        - 단점

          - 특정 프로토콜을 이용해야 스위칭 가능

          <br>

     3. L4(Transport Layer)

        - L4 rPcmddptj ehdwkr
        - 네트워크 계층(IP, IPX)이나 트랜스포트 계층(TCP, UDP)의 정보를 바탕으로 부하를 분산
          - **Transport Layer(IP와 port) 바탕**으로 로드 밸런싱
          - 이러한 이유로 L4 로드 밸런서를 CLB(Connect)나 SLB(Session)라고 부르기도 한다
        - 장점
          - Port 기반 스위칭 지원, VIP를 이용하여 여러 대를 한대로 묶어 부하 분산
        - 주로 라운드 로빈 방식 사용

        <br>

     4. L7(Application Layer)

        - **Application Layer(사용자의 Request) 레벨**에서 로드 밸런싱
        - L4의 기능을 포함하는 것 뿐만 아니라 애플리케이션 계층(HTTP, SMTP, FTP)의 정보를 바탕으로도 분산 처리 가능
        - URL에 따라 부하를 분산하거나, HTTP 헤더의 쿠키 값에 따라 부하를 분산하는 등 클라이언트의 요청을 보다 세분화해 서버에 전달할 수 있다
        - 특정한 패턴을 지닌 바이러스를 감지해 네트워크를 보호할 수 있으며, Dos/DDos와 같은 비정상적 트래픽을 필터링할 수 있어 네트워크 보안 분야에서도 활용

        <br>

        - L7 로드 밸런싱 방법
          1. URL 스위칭 방식
             - 특정 하위 URL들은 특정 서버로 처리하는 방식
             - ex
               -  '.../images' 또는 '.../video'와 같은 URL은 서버가 아닌 별도의 스토리지에 있는 객체 데이터로 바로 연결되도록 구성할 수 있다
          2. 컨텍스트 스위칭 방식
             - 클라이언트가 요청한 특정 리소스에 따라 특정 서버로 연결할 수 있다
             - ex
               - 이미지 파일에 대해서는 확장자를 참조해 별도로 구성된 이미지 파일이 있는 서버 또는 스토리지로 직접 연결해 줄 수 있다
          3. 쿠키 지속성
             - 쿠키 정보를 바탕으로 클라이언트가 연결했었던 서버에 계속 할당해 주는 방식

     <br>

     :ballot_box_with_check: L4와 L7의 차이

     - 일반적으로 로드밸런서는 크게 L4와 L7 사용

     <br>

     - 공통점

       - 들어온 packet을 적절한 목적지로 전달(스위칭)
       - 적절한 알고리즘을 통해 로드밸런서로서의 역할 수행
       - 스위치 및 서버별 Health Check

     - 차이점

       - L4는 단지 부하를 분산시키는 것이라면, L7은 요청의 세부적인 사항을 두고 결제만 담당하는 서버, 회원가입을 담당하는 서버 등으로 분리해 가볍고 작은 단위로 여러 개의 서비스를 운영하고 요청을 각각의 서버에 분산
       - L7은 L4와 다르게 데이터를 분석해 처리가 가능하기 때문에 악의적이거나 비정상적인 콘텐츠를 감지해 보안 지점을 구축할 수 있는 장점과 그만큼 자원 소모가 크다는 단점

<br>

:heavy_check_mark:로드 밸런서 동작 방식(L4 기준)

- 클라이언트가 브라우저에서 'www.google.com'이라고 입력하면 PC에 설정된 DNS 서버로 DNS 쿼리를 보내고, 로컬 DNS 서버는 'www.google.com'을 관리하는 DNS 서버로부터 L4의 VIP 주소를 획득
- 로컬 DNS는 획득한 VIP 주소를 클라이언트에게 전송
- 클라이언트는 획득한 DNS를 기반으로 L4 VIP로 http(s) 요청
- LB는 최적의 서비스 서버를 내부 알고리즘을 통해 선별한 후 요청을 전송하고, 서버 작업 결과를 LB에게 전송
- 전달받은 결과를 LB를 통해 클라이언트에게 전송



<br>

:heavy_check_mark: 로드 밸런서 기본 기능

1. 상태 확인(Health Check)

   - **서버들에 대한 주기적인 상태 확인을 통해 서버들의 장애 여부를 판단**할 수 있다
   - 서버에 이상이 생기면 정상적으로 동작하는 서버로 트래픽을 보내주는 Fail-Over가 기능
   - TCP/UDP 분석이 가능하기 때문에 방화벽의 역할도 수행

   <br>

2. Tunneling

   - **인터넷 상에서 눈에 보이지 않는 통로를 만들어 통신**할 수 있게 하는 개념
   - **데이터를 캡슐화**해 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있다
     - 패킷을 캡슐화해 연결된 상호간에만 패킷을 구별할 수 있게 해준다
   - 로드밸런서의 VIP 주소로 향하는 요구 패킷이 로드 밸런싱 서버로 전달되면 로드 밸런싱 서버에서 패킷의 목적지 주소와 포트를 검사하여 가상 서버 정책과 일치할 경우, 스케줄링에 따라 실제 작업 서버로 전달
   - 이때 패킷을 일반적인 스트림 방식으로 전달하는 것이 아닌 캡슐 형식으로 감싸서 전달
   - 이렇게 전달되면 작업 서버에서는 감싸진 패킷을 다시 풀고 요청을 처리

   <br>

3. NAT(Network Address Translation)

   - **IP 주소를 변환해 주는 기능**

   - 내부 네트워크에서 사용하던 사설 IP 주소를 로드 밸런서 외부의 공인 IP 주소로 변경해주며, 반대 과정도 가능

   - 이렇게 하면 부족한 공인 IP 주소를 효율적으로 사용할 수 있지만, **로드 밸런싱 관점에서는 여러개의 호스트가 하나의 공인 IP 주소(VIP)를 통해 접속하는 것이 주 목적**

     <br>

     1. SNAT(Source)
        - 내부에서 외부로 트래픽이 나가는 경우, **내부** 사설 IP 주소를 외부 공인 IP 주소로 **변환**하는 방식
        - 집에서 사용하는 공유기가 대표적 예시
     2. DNAT(Destination)
        - 외부에서 내부로 트래픽이 들어오는 경우, **외부** 공인 IP 주소를 **내부** 사설 IP 주소로 변환하는 방식

   <br>

4. DSR(Direct Server Routing)

   - 서버에서 클라이언트로 되돌아가는 경우, 목적지를 클라이언트로 설정한 다음 **네트워크 장비나 로드 밸런서를 거치지 않고 바로 클라이언트로 찾아가는 방식**
   - 로드 밸런서의 부하를 줄여줄 수 있는 장점

   <br>

:heavy_check_mark: 로드 밸런서 장애 대비

- 갑작스러운 장애에 대비해 로드 밸런서 서버는 `이중화`를 기본으로 구성

  ```
  [Fail Over]
  1. 이중화된 로드 밸런서들은 서로 상태를 확인한다
  2. Master 서버가 Fail되면 Standby 서버가 자동으로 Master 서버의 역할을 한다
  3. Standby 서버는 평상시에는 대기 상태로 있다가 Master 서버가 Fail되었을 경우에만 작동
  ```

  
